{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0532053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #To retrieve inputs from the webcam\n",
    "import dlib #To detect keypoints from a face\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "daa693e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() #To detect one or more faces\n",
    "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat') # detecting keypoints from faces\n",
    "cap = cv2.VideoCapture(0) # To capture images from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac3df5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524fada",
   "metadata": {},
   "source": [
    "### Draw rectangle around eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5679e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, color):\n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eyes = eye_cascade.detectMultiScale(image, scaleFactor = 1.2,\n",
    "                                        minNeighbors = 4)\n",
    "    for (x,y,w,h) in eyes:\n",
    "                cv2.rectangle(image,(x,y),(x+w,y+h),color,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c99933c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_ear(eye):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical eye landmarks (x, y)-coordinates\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    "\t# compute the eye aspect ratio\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\t# return the eye aspect ratio\n",
    "\treturn ear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b5ffa",
   "metadata": {},
   "source": [
    "### Check if the eye is closed or opened by calculating the ear of each eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06d709dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ear(ear,treshold):\n",
    "    if ear < treshold:\n",
    "            draw_rectangle(image, (0,0,255))\n",
    "            cv2.putText(image, \"closed eyes, WARNING!!\",(50, 50),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1,(0, 0, 255),2, cv2.LINE_AA ) \n",
    "    else:\n",
    "            draw_rectangle(image, (0,255,255))\n",
    "            cv2.putText(image, 'opened eyes',(50, 50),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,(255, 0, 0),2, cv2.LINE_AA )\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9b6d6",
   "metadata": {},
   "source": [
    "### Display eye landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "657d1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eye_landmarks(eye):\n",
    "    for i, (x, y) in enumerate(eye):\n",
    "            cv2.circle(image, (x, y), 1, (255, 0, 255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1faef68f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rr/62tz31v139gdkk0h36fmvq240000gn/T/ipykernel_3249/744542613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Detect the face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Detect landmarks for each face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Capture the image from the webcam\n",
    "    ret,image = cap.read()\n",
    "\n",
    "    # Convert the image color to grayscale\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect the face\n",
    "    \n",
    "    rects = detector(gray, 1)\n",
    "    \n",
    "    # Detect landmarks for each face\n",
    "    \n",
    "    for rect in rects:\n",
    "        \n",
    "        # Get the landmark points\n",
    "        shape = predictor(gray, rect)\n",
    "        \n",
    "\t    # Convert it to the NumPy Array\n",
    "        shape_np = np.zeros((68, 2), dtype=\"int\")\n",
    "\n",
    "        for i in range(0, 68):\n",
    "            shape_np[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        shape = shape_np\n",
    "        \n",
    "        #Define the left eye landmarks\n",
    "        \n",
    "        left_eye = np.zeros((6, 2), dtype=\"int\")\n",
    "        for j in range(0,6):\n",
    "            left_eye[j] = shape[42 + j]\n",
    "\n",
    "        #define the right eye landmarks\n",
    "        \n",
    "        right_eye = np.zeros((6, 2), dtype=\"int\")\n",
    "        for j in range(0,6):\n",
    "            right_eye[j] = shape[36 + j]\n",
    "            \n",
    "        # Display the landmarks\n",
    "        \n",
    "        #display_eye_landmarks(left_eye)\n",
    "\n",
    "        #display_eye_landmarks(right_eye)\n",
    "       \n",
    "        #Calculate the ear\n",
    "        \n",
    "        right_ear = eye_ear(right_eye)\n",
    "        left_ear = eye_ear(left_eye)\n",
    "        \n",
    "        ear = (left_ear + right_ear) / 2.0\n",
    "        \n",
    "        # check to see if the eye ear is below the threshold\n",
    "        check_ear(ear,THRESH)\n",
    "          \n",
    "    # Display the image\n",
    "    cv2.imshow('Landmark Detection', image)\n",
    "\n",
    "    # Press the escape button to terminate the code\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670a239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
